{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load('/home/abdussamad/github/portfolio-manager/BackTest/inputs.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arr_0', 'arr_1']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, ys = f['arr_0'], f['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs[:, 0, 1].reshape(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = Xs[:, 0, 1].reshape(-1, 1, 1).copy()\n",
    "Xs[:, :, [5]] /= scales\n",
    "Xs[:, :, :4] /= scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plt.plot(Xs[399950, :, i])\n",
    "plt.plot(Xs[399950, :, 5])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bresenham(img, x0, y0, x1, y1):\n",
    "    dx = abs(x1 - x0)\n",
    "    sx = 1 if x0 < x1 else -1 \n",
    "    dy = -abs(y1 - y0)\n",
    "    sy = 1 if y0 < y1 else -1\n",
    "    error = dx + dy\n",
    "\n",
    "    while True:\n",
    "        img[x0, y0] = 255\n",
    "        if x0 == x1 and y0 == y1:\n",
    "            break\n",
    "        e2 = 2 * error\n",
    "        if e2 >= dy:\n",
    "            if x0 == x1:\n",
    "                break \n",
    "            error += dy\n",
    "            x0 += sx\n",
    "        if e2 <= dx:\n",
    "            if y0 == y1:\n",
    "                break\n",
    "            error += dx\n",
    "            y0 += sy\n",
    "\n",
    "def make_image(sample, ema=True, volume=True):\n",
    "    height_bars = 96\n",
    "    width = sample.shape[0] * 3\n",
    "    img_ohlc = np.zeros((width, height_bars), dtype=np.uint8)\n",
    "\n",
    "    max_price = max(sample[:, :4].max(), sample[:, 5].max())\n",
    "    min_price = min(sample[:, :4].min(), sample[:, 5].min())\n",
    "    height_scaler = (height_bars - 1) / (max_price - min_price)\n",
    "\n",
    "    ema_y_prev = None\n",
    "\n",
    "    for t in range(sample.shape[0]):\n",
    "        open_y = round((sample[t, 1] - min_price) * height_scaler)\n",
    "        img_ohlc[3*t, open_y] = 255\n",
    "        close_y = round((sample[t, 0] - min_price) * height_scaler)\n",
    "        img_ohlc[3*t+2, close_y] = 255\n",
    "\n",
    "        low_y = round((sample[t, 3] - min_price) * height_scaler)\n",
    "        high_y = round((sample[t, 2] - min_price) * height_scaler)\n",
    "        img_ohlc[3*t+1, low_y:high_y] = 255\n",
    "\n",
    "        if ema:\n",
    "            ema_y = round((sample[t, 5] - min_price) * height_scaler)\n",
    "            img_ohlc[3*t+1, ema_y] = 255\n",
    "            if ema_y_prev is not None:\n",
    "                bresenham(img_ohlc, 3*t-2, ema_y_prev, 3*t+1, ema_y)\n",
    "            ema_y_prev = ema_y\n",
    "\n",
    "    if not volume:\n",
    "        return img_ohlc.T\n",
    "    \n",
    "    height_vol = 24\n",
    "    height_whole = height_bars + height_vol if volume else 0\n",
    "    img_whole = np.zeros((width, height_whole), dtype=np.uint8)\n",
    "    img_whole[:, :height_bars] = img_ohlc\n",
    "\n",
    "    max_vol = sample[:, 4].max()\n",
    "    vol_scaler = (height_vol - 1)/max_vol \n",
    "    for t in range(sample.shape[0]):\n",
    "        vol_y = round(sample[t, 4] * vol_scaler)\n",
    "        img_whole[3*t+1, height_whole-vol_y-1:height_whole-1] = 255\n",
    "\n",
    "    return img_whole.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 64, kernel_size=(5, 3), padding=1),\n",
    "            torch.nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            torch.nn.MaxPool2d((2, 1))\n",
    "        )\n",
    "        self.block2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=(5, 3), padding=1),\n",
    "            torch.nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            torch.nn.MaxPool2d((2, 1))\n",
    "        )\n",
    "        self.out_block = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(161280, 2),\n",
    "            torch.nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.out_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_pt = torch.LongTensor(ys > 0)\n",
    "xs_pt = torch.zeros(size=(Xs.shape[0], 120, 45), dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Xs.shape[0]):\n",
    "    xs_pt[i] = torch.tensor(make_image(Xs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = round(ys_pt.shape[0] * 0.85)\n",
    "ys_train, ys_valid = ys_pt[:split_idx], ys_pt[split_idx:]\n",
    "xs_train, xs_valid = xs_pt[:split_idx], xs_pt[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train(0.6910760296973744, 52.82), Valid(0.6893467584519845, 53.78)\n",
      "Epoch 2: Train(0.6896473602427685, 53.31), Valid(0.6895116291129466, 53.75)\n",
      "Epoch 3: Train(0.6878780919489746, 54.09), Valid(0.6897134968361465, 53.62)\n",
      "Epoch 4: Train(0.6854344285020784, 54.97), Valid(0.6907506457768896, 53.33)\n",
      "Epoch 5: Train(0.6822858538280676, 55.95), Valid(0.6938396371291496, 52.34)\n",
      "Epoch 6: Train(0.6784544911104483, 57.01), Valid(0.6946173781341177, 52.74)\n",
      "Epoch 7: Train(0.6740767819824951, 58.11), Valid(0.6971454615627043, 52.51)\n",
      "Epoch 8: Train(0.6693739806153439, 59.09), Valid(0.7007452581873765, 51.94)\n",
      "Epoch 9: Train(0.6645216924452638, 60.08), Valid(0.7037544005725761, 51.86)\n",
      "Epoch 10: Train(0.6597307378641105, 61.03), Valid(0.7064903944233659, 52.05)\n",
      "Epoch 11: Train(0.6548079588245113, 61.94), Valid(0.7100279336888418, 51.64)\n",
      "Epoch 12: Train(0.6501953152023892, 62.73), Valid(0.7138528955939083, 51.40)\n",
      "Epoch 13: Train(0.6457489973596615, 63.46), Valid(0.7184792677024889, 51.23)\n",
      "Epoch 14: Train(0.6413994311835143, 64.22), Valid(0.7175016572685635, 51.72)\n",
      "Epoch 15: Train(0.6372130901502991, 64.89), Valid(0.7220880885366602, 51.47)\n",
      "Epoch 16: Train(0.6331363504688018, 65.54), Valid(0.7278392380244018, 51.08)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_hat, ys)\n\u001b[1;32m     32\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 34\u001b[0m train_total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     35\u001b[0m train_n_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     36\u001b[0m train_n_hits \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39margmax(y_hat, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m ys)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds_train = torch.utils.data.TensorDataset(xs_train, ys_train)\n",
    "ds_valid = torch.utils.data.TensorDataset(xs_valid, ys_valid)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "m = StockCNN()\n",
    "m = m.to(DEVICE)\n",
    "opt = torch.optim.Adam(m.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# ds_train_bs = torch.utils.data.TensorDataset(xs_train[:BATCH_SIZE], ys_train[:BATCH_SIZE])\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    train_total_loss = 0\n",
    "    train_n_batches = 0\n",
    "    train_n_hits = 0\n",
    "    train_n_total = 0\n",
    "\n",
    "    for xs, ys in dl_train:\n",
    "        xs = xs.to(DEVICE)\n",
    "        xs = xs.unsqueeze(1).float() / 255.0\n",
    "        ys = ys.to(DEVICE).squeeze()\n",
    "        opt.zero_grad()\n",
    "        y_hat = m(xs)\n",
    "        loss = loss_fn(y_hat, ys)\n",
    "        loss.backward()\n",
    "\n",
    "        train_total_loss += loss.cpu().item()\n",
    "        train_n_batches += 1\n",
    "        train_n_hits += (torch.argmax(y_hat, dim=-1) == ys).sum().cpu().item()\n",
    "        train_n_total += y_hat.shape[0]\n",
    "\n",
    "\n",
    "        # print(f'Loss={loss.cpu().item()}, {(torch.argmax(y_hat, dim=-1) == ys).sum().cpu().item()/y_hat.shape[0]}')\n",
    "        opt.step()\n",
    "\n",
    "    valid_total_loss = 0\n",
    "    valid_n_batches = 0\n",
    "    valid_n_hits = 0\n",
    "    valid_n_total = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for xs, ys in dl_valid:\n",
    "            xs = xs.to(DEVICE)\n",
    "            xs = xs.unsqueeze(1).float() / 255.0\n",
    "            ys = ys.to(DEVICE).squeeze()\n",
    "            y_hat = m(xs)\n",
    "            loss = loss_fn(y_hat, ys)\n",
    "            \n",
    "            valid_total_loss += loss.cpu().item()\n",
    "            valid_n_batches += 1\n",
    "            valid_n_hits += (torch.argmax(y_hat, dim=-1) == ys).sum().cpu().item()\n",
    "            valid_n_total += y_hat.shape[0]     \n",
    "\n",
    "    print(f'Epoch {ep+1}: Train({train_total_loss/train_n_batches}, {100.0 * train_n_hits/train_n_total:.2f}), Valid({valid_total_loss/valid_n_batches}, {100.0 * valid_n_hits/valid_n_total:.2f})')       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xs[0, 0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(y_hat, ys.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pt = torch.stack([torch.FloatTensor(x)/255.0 for x in batch])\n",
    "batch_pt = batch_pt.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = m(batch_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "128 * 28 * 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1.0579706111328149 - 0.9999994104739358) * 1655.9946819955387"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_price = max(x[:, :4].max(), x[:, 5].max())\n",
    "min_price = min(x[:, :4].min(), x[:, 5].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(make_image(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(make_image(Xs[1843]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(make_image(Xs[18343]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_series = np.cumprod(Xs2 + 1, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
